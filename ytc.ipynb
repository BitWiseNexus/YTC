{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742e5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q youtube-transcript-api langchain-community langchain-google-genai faiss-cpu tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf5f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain) (1.0.0)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Using cached langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached ormsgpack-1.11.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\genai projects\\ytc\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Using cached langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Using cached langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Using cached ormsgpack-1.11.0-cp312-cp312-win_amd64.whl (112 kB)\n",
      "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "Successfully installed langchain-1.0.2 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.11.0 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca517a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8ea798",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=Gfr50f6ZBvo\"\n",
    "\n",
    "try:\n",
    "    # Initialize and load transcript\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url, add_video_info=False)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Combine all chunks into a single string\n",
    "    transcript = \" \".join(doc.page_content for doc in docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Transcript could not be loaded:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e844c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1700, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e03bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ea861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "037b3bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added documents 0 to 10\n",
      "Added documents 10 to 20\n",
      "Added documents 20 to 30\n",
      "Added documents 30 to 40\n",
      "Added documents 40 to 50\n",
      "Added documents 50 to 60\n",
      "Added documents 60 to 70\n",
      "Added documents 70 to 80\n",
      "Added documents 80 to 90\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\", google_api_key=key)\n",
    "\n",
    "for i in range(0,len(chunks),10):\n",
    "    if(i==0):\n",
    "        vectorstore = FAISS.from_documents(chunks[i:i+10], embedding=embeddings)\n",
    "    else:\n",
    "        vectorstore.add_documents(chunks[i:i+10])\n",
    "    print(f\"Added documents {i} to {i+10}\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff72c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83fb9149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020951BE25D0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f9a5a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='94789430-cdb5-4119-bda6-9b9372a8d23d', metadata={}, page_content=\"the the entertainment right you're actually actively involved as an as a as an agent so i think that's what makes it in some ways can be more visceral than other other mediums like you know films and books so the second so that was you know designing ai and games and then the third use uh uh i've we've used of ai is in deep mind from the beginning which is using games as a testing ground for proving out ai algorithms and developing ai algorithms and that was a that was a sort of um a core component of our vision at the start of deepmind was that we would use games very heavily uh as our main testing ground certainly to begin with um because it's super efficient to use games and also you know it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements and because those games are often rooted in something that humans did for a long time beforehand there's already a strong set of rules like it's already a damn good benchmark yes it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things and in some cases like go we've been playing it for thousands of years um and and uh often they have scores or at least win conditions so it's very easy for reward learning systems to get a reward it's very easy to specify what that reward is um and uh also at the end it's easy to you know to test uh externally you know how strong is your system by of course playing against you know the world's strongest players at those games so it's it's so good for so many reasons and it's also very efficient to run\"),\n",
       " Document(id='9438691a-b34b-4fec-aeb3-f6389dcaf431', metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough to interview you well i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet but uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language model that's tasked with interviewing that it is in fact um ai maybe we're in a kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your behavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's happening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were good\"),\n",
       " Document(id='baebc1c8-e66f-40d5-b900-bca08c0a7e13', metadata={}, page_content=\"know no one was talking about it i did a postdoc at mit back around then and it was sort of thought of as a well look we know ai doesn't work we tried this hard in the 90s at places like mit mostly losing using logic systems and old-fashioned sort of good old-fashioned ai we would call it now um people like minsky and and and patrick winston and you know all these characters right and used to debate a few of them and they used to think i was mad thinking about that some new advance could be done with learning systems and um i was actually pleased to hear that because at least you know you're on a unique track at that point right even if every all of your you know professors are telling you you're mad that's true and of course in industry uh you can we couldn't get you know as difficult to get two cents together uh and which is hard to imagine now as well given it's the biggest sort of buzzword in in vcs and and fundraising's easy and all these kind of things today so back in 2010 it was very difficult and what we the reason we started then and shane and i used to discuss um uh uh what were the sort of founding tenets of deep mind and it was very various things one was um algorithmic advances so deep learning you know jeff hinton and cohen just had just sort of invented that in academia but no one in industry knew about it uh we love reinforcement learning we thought that could be scaled up but also understanding about the human brain had advanced um quite a lot uh in the decade prior with fmri machines and other things so we could get some good hints about architectures and algorithms and and sort of um representations maybe that the brain uses so as at a systems level\"),\n",
       " Document(id='7f7618fd-9469-4c4a-85c2-55daee373130', metadata={}, page_content=\"you're studying it doesn't exist out in nature you have to build it first so you have to build the artifact first and then you can study how how and pull it apart and how it works this is tough to uh ask you this question because you probably will say it's everything but let's let's try let's try to think to this because you're in a very interesting position where deepmind is the place of some of the most uh brilliant ideas in the history of ai but it's also a place of brilliant engineering so how much of solving intelligence this big goal for deepmind how much of it is science how much is engineering so how much is the algorithms how much is the data how much is the hardware compute infrastructure how much is it the software computer infrastructure yeah um what else is there how much is the human infrastructure and like just the humans interact in certain kinds of ways in all the space of all those ideas how much does maybe like philosophy how much what's the key if um uh if if you were to sort of look back like if we go forward 200 years look back what was the key thing that solved intelligence is that ideas i think it's a combination first of all of course it's a combination of all those things but the the ratios of them changed over over time so yeah so um even in the last 12 years so we started deep mine in 2010 which is hard to imagine now because 2010 it's only 12 short years ago but nobody was talking about ai uh you know if you remember back to your mit days you know no one was talking about it i did a postdoc at mit back around then and it was sort of thought of as a well look we know ai doesn't work we tried this hard in the 90s at places like mit mostly\")]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('What is deepmind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3566a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    google_api_key=key, \n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72fa523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "      \n",
    "      {context}\n",
    "\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "290d6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs    = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d34e30b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ab7d9834-db90-4c87-9fa9-533de996f8a4', metadata={}, page_content=\"problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can ai eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and simulate arbitrary quantum mechanical systems in the future yeah so this is another problem i've had my eye on for you know a decade or more which is um uh sort of simulating the properties of electrons if you can do that you can basically describe how elements and materials and substances work so it's kind of like\"),\n",
       " Document(id='70e5d3b7-1ba5-4592-8137-963688e1f651', metadata={}, page_content=\"like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of view and that would address one of their bottlenecks and in this case plasma control was was perfect so you know the plasma it's a million degrees celsius something like that it's hotter than the sun and there's obviously no material that can contain it so they have to be containing these magnetic very powerful superconducting magnetic fields but the problem is plasma is pretty unstable as you imagine you're kind of holding a mini sun mini star in a reactor so you know you you kind of want to predict ahead of time what the plasma's going to do so you can move the magnetic field within a few milliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know your controller you're gonna move the magnetic field and until we came along you know they were they were doing it with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn\"),\n",
       " Document(id='daa49fe7-ec7a-4c9a-9fe6-173497e0bb11', metadata={}, page_content=\"what's what kind of intelligence that is that's a pretty powerful intelligence if you know how to use that and integrate that information correctly yes i think you can go really far you can probably construct thought experiments based on that like simulate different ideas so if this is true let me run this thought experiment then maybe this is true it's not really invention it's like just taking literally the knowledge and using it to construct a very basic simulation of the world i mean some argue it's romantic in part but einstein would do the same kind of things with a thought experiment yeah one could imagine doing that systematically across millions of wikipedia pages plus pubmed all these things i think there are many many things to be discovered like that they're hugely useful you know you could imagine and i want us to do some of those things in material science like room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would\"),\n",
       " Document(id='094daba3-e9fd-48ba-9656-715c834fe55d', metadata={}, page_content=\"been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc94248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can ai eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and simulate arbitrary quantum mechanical systems in the future yeah so this is another problem i've had my eye on for you know a decade or more which is um uh sort of simulating the properties of electrons if you can do that you can basically describe how elements and materials and substances work so it's kind of like\\n\\nlike fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of view and that would address one of their bottlenecks and in this case plasma control was was perfect so you know the plasma it's a million degrees celsius something like that it's hotter than the sun and there's obviously no material that can contain it so they have to be containing these magnetic very powerful superconducting magnetic fields but the problem is plasma is pretty unstable as you imagine you're kind of holding a mini sun mini star in a reactor so you know you you kind of want to predict ahead of time what the plasma's going to do so you can move the magnetic field within a few milliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know your controller you're gonna move the magnetic field and until we came along you know they were they were doing it with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn\\n\\nwhat's what kind of intelligence that is that's a pretty powerful intelligence if you know how to use that and integrate that information correctly yes i think you can go really far you can probably construct thought experiments based on that like simulate different ideas so if this is true let me run this thought experiment then maybe this is true it's not really invention it's like just taking literally the knowledge and using it to construct a very basic simulation of the world i mean some argue it's romantic in part but einstein would do the same kind of things with a thought experiment yeah one could imagine doing that systematically across millions of wikipedia pages plus pubmed all these things i think there are many many things to be discovered like that they're hugely useful you know you could imagine and i want us to do some of those things in material science like room temperature superconductors or something on my list one day i'd like to like you know have an ai system to help build better optimized batteries all of these sort of mechanical things mr i think a systematic sort of search could be uh guided by a model could be um could be extremely powerful so speaking of which you have a paper on nuclear fusion uh magnetic control of tokamak plasmas to deep reinforcement learning so you uh you're seeking to solve nuclear fusion with deep rl so it's doing control of high temperature plasmas can you explain this work and uh can ai eventually solve nuclear fusion it's been very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would\\n\\nbeen very fun last year or two and very productive because we've been taking off a lot of my dream projects if you like of things that i've collected over the years of areas of science that i would like to i think could be very transformative if we helped accelerate and uh really interesting problems scientific challenges in of themselves this is energy so energy yes exactly so energy and climate so we talked about disease and biology as being one of the biggest places i think ai can help with i think energy and climate uh is another one so maybe they would be my top two um and fusion is one one area i think ai can help with now fusion has many challenges mostly physics material science and engineering challenges as well to build these massive fusion reactors and contain the plasma and what we try to do whenever we go into a new field to apply our systems is we look for um we talk to domain experts we try and find the best people in the world to collaborate with um in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27d602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efb32e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the topic of nuclear fusion is discussed in the video.\n",
      "\n",
      "What was discussed:\n",
      "*   AI is being applied to help solve nuclear fusion challenges.\n",
      "*   A specific problem in fusion, controlling and holding plasma in specific shapes (almost like carving it) for record amounts of time, was addressed using AI (deep reinforcement learning). This is considered one of the \"bottleneck problems\" of fusion.\n",
      "*   Plasma control is crucial because plasma is extremely hot (millions of degrees Celsius, hotter than the sun) and unstable, requiring containment by powerful superconducting magnetic fields.\n",
      "*   AI can predict plasma behavior and adjust the magnetic field within milliseconds, which traditional hard-coded controllers cannot do in the moment.\n",
      "*   The work involved collaboration with EPFL in Switzerland, using their test reactor.\n",
      "*   Fusion still faces many challenges, including physics, material science, and engineering.\n",
      "*   The strategy is to identify bottleneck problems in fusion that are amenable to AI methods.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959fbd58",
   "metadata": {},
   "source": [
    "# Building the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a86ceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cccbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "    context_text= \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c04429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain=RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a675192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"thanks for listening to this conversation with demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than astronomy is about telescopes thank you for listening and hope to see you next time\\n\\nthe following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough to interview you well i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet but uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language model that's tasked with interviewing that it is in fact um ai maybe we're in a kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your behavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's happening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were good\\n\\nthe excuse me exactly all right let me i don't have time to explain uh maybe i'll draw you a picture that it is i mean how do you even begin um to answer that question well i think it would um what would you what would you think the answer could possibly look like i think it could it could start looking like uh uh more fundamental explanations of physics would be the beginning you know more careful specification of that taking you walking us through by the hand as to what one would do to maybe prove those things out maybe giving you glimpses of what things you totally missed in the physics of today exactly just here here's glimpses of no like there's a much uh a much more elaborate world or a much simpler world or something a much deeper maybe simpler explanation yes of things right than the standard model of physics which we know doesn't work but we still keep adding to so um and and that's how i think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know consciousness uh life and gravity all of these things yeah giving us a glimpses of explanations for those things yeah well um damas dear one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you thank you i really enjoyed it thanks lex thanks for listening to this conversation with demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra\\n\\nhow do you deal with pressure sort of test yourself in various scenarios and try and improve your weaknesses but also find out what your unique skills and strengths are and then hone those so then that's what will be your super value in the world later on and if you can then combine those two things and find passions that you're genuinely excited about that intersect with what your unique strong skills are then you're you know you're on to something incredible and and you know i think you can make a huge difference in the world so let me ask about know yourself this is fun this is fun quick questions about day in the life the perfect day the perfect productive day in the life of demise's house yeah maybe uh maybe these days you're um there's a lot involved yeah it may be a slightly younger you could focus on a demonstration project maybe um how early do you wake up are you night owl do you wake up early in the morning what are some interesting habits uh how many dozens of cups of coffees do you drink a day what's the computer um that you use uh what's the setup how many screens what kind of keyboard are we talking uh emacs vim are we talking something more modern so it's a bunch of those questions so maybe uh day in the life what what's the perfect day involved well these days it's quite different from say 10 20 years ago back 10 20 years ago it would have been you know a whole day of research individual research or programming doing some experiment neuroscience computer science experiment reading lots of research papers uh and then perhaps at night time you know um reading science fiction books or or uh playing uh some games but lots of focus so like deep focused work\",\n",
       " 'question': 'Who is Demis'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke(\"Who is Demis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00d9a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b4375a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain=parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f548e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The conversation covers several topics:\\n\\n1.  **AI and Human Interaction**: The speaker discusses the idea of AI systems getting frustrated and the belief that true intelligence should be able to explain complex concepts simply. They also touch upon human enhancement through compute devices like phones and potential future technologies like Neuralink.\\n2.  **Existence of Alien Civilizations**: Based on current evidence and the lack of signals from programs like SETI, the speaker's personal opinion is that humanity is likely alone in the universe.\\n3.  **AI Development Methodology (DeepMind's Alpha series)**: The discussion highlights the strategy of letting learning flow end-to-end in AI systems, starting with small learning components and expanding them. This is exemplified by the evolution of AlphaGo (trained for Go) to AlphaGo Zero (learned without human games), then AlphaZero (generalized to any two-player game without specific rules), and finally MuZero (which doesn't even need the game rules).\\n4.  **Fundamental Physics and Mysteries**: The speaker speculates on how a more fundamental explanation of physics might look, suggesting it could offer simpler explanations for long-standing mysteries such as consciousness, life, and gravity, going beyond the current standard model.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke(\"Summarize the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b39da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
